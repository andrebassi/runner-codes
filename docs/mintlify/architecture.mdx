---
title: 'Architecture'
description: 'Deep dive into LLM-Firecracker system architecture'
---

## System Overview

LLM-Firecracker uses a layered architecture designed for security, performance, and scalability.

<Frame>
  <img src="/images/system-architecture.svg" alt="System Architecture" />
</Frame>

## Component Details

### Host Mode (infra.operator host)

The host mode is the main orchestrator running on the EC2 host. It manages the lifecycle of Firecracker microVMs and handles job execution.

<CodeGroup>
```go pkg/host/runner.go
// Runner handles VM lifecycle and code execution
type Runner struct {
    config *RunnerConfig
    fc     *FirecrackerClient
    cache  *SnapshotCache
}

// Run executes code in a microVM
func (r *Runner) Run() (*RunResult, error) {
    // 1. Ensure snapshot is cached (download from S3 if needed)
    // 2. Start Firecracker with snapshot restore
    // 3. Connect via vsock
    // 4. Send job, receive result
    // 5. Shutdown VM
}
```

```go pkg/host/firecracker.go
// Firecracker API calls
PUT /machine-config     {"vcpu_count":1,"mem_size_mib":512,"smt":false}
PUT /boot-source        {"kernel_image_path":"...","boot_args":"..."}
PUT /drives/rootfs      {"drive_id":"rootfs","path_on_host":"..."}
PUT /vsock              {"guest_cid":3,"uds_path":"/tmp/fc.vsock"}
PUT /actions            {"action_type":"InstanceStart"}
PUT /actions            {"action_type":"SendCtrlAltDel"}
```
</CodeGroup>

### Guest Mode (infra.operator guest)

The guest mode executes inside the microVM and handles code execution requests.

```go pkg/guest/executor.go
type Executor struct {
    languages map[string]LanguageConfig
}

type LanguageConfig struct {
    Name       string   // "python", "node", etc.
    Extension  string   // ".py", ".js", etc.
    Command    string   // "python3", "node", etc.
    Args       []string // Additional arguments
    NeedsBuild bool     // For compiled languages
    BuildCmd   string   // "rustc", "go", etc.
    BuildArgs  []string // Build arguments
}

func (e *Executor) Execute(job Job) Result {
    // 1. Create temp directory
    // 2. Write code to file
    // 3. Execute (or compile then execute)
    // 4. Capture stdout/stderr
    // 5. Return result
}
```

### Vsock Communication

The host and guest communicate via virtio-vsock, a virtual socket for VM-to-host communication.

<Steps>
  <Step title="Host connects to Firecracker UDS">
    ```
    connect(/tmp/fc-{instance_id}.vsock)
    ```
  </Step>
  <Step title="Host sends CONNECT command">
    ```
    CONNECT 5000\n
    ```
  </Step>
  <Step title="Guest accepts connection">
    ```
    OK 5000\n
    ```
  </Step>
  <Step title="Message exchange begins">
    Messages use 4-byte big-endian length prefix + JSON payload
  </Step>
</Steps>

## Data Flow

### Job Execution Flow

<Frame>
  <img src="/images/data-flow.svg" alt="Data Flow" />
</Frame>

### Boot Timeline

| Phase | Duration | Description |
|-------|----------|-------------|
| Firecracker API calls | ~100ms | Configure VM via API socket |
| Kernel boot | ~900ms | Linux kernel initialization |
| Systemd init | ~1.5s | Service startup |
| Infra.operator guest ready | ~500ms | Vsock server listening |
| **Total cold boot** | **~3s** | Full boot time |

With snapshot restore:
| Phase | Duration | Description |
|-------|----------|-------------|
| Load snapshot | ~50ms | Restore VM state |
| Resume VM | ~20ms | Continue execution |
| **Total warm start** | **~70ms** | Snapshot restore time |

## Security Model

### Isolation Layers

<AccordionGroup>
  <Accordion title="VM-Level Isolation">
    Each code execution runs in its own Firecracker microVM:
    - Separate kernel instance
    - Isolated memory space
    - Independent file system
    - No shared resources with host
  </Accordion>

  <Accordion title="Network Isolation">
    By default, microVMs have no network access:
    - No network interfaces configured
    - No DNS resolution
    - Cannot make outbound connections
    - Only vsock for host communication
  </Accordion>

  <Accordion title="Filesystem Isolation">
    Each VM has its own rootfs:
    - Read-write access within VM
    - Changes don't persist after shutdown
    - Fresh filesystem for each execution
  </Accordion>

  <Accordion title="Resource Limits">
    Configurable resource constraints:
    - vCPU count (default: 1)
    - Memory limit (default: 512 MiB)
    - Execution timeout (configurable per job)
  </Accordion>
</AccordionGroup>

### Security Features (Production)

<Warning>
  The following features are recommended for production but not yet implemented:
</Warning>

| Feature | Status | Description |
|---------|--------|-------------|
| Jailer | Planned | chroot + dropped capabilities |
| Seccomp | Planned | Per-language syscall filtering |
| Read-only rootfs | Planned | Overlay filesystem for writes |
| cgroups | Planned | Resource enforcement |
| eBPF | Planned | Network blocking |

## Storage Architecture

### S3-Backed Rootfs

Rootfs images are stored in S3 and downloaded on demand:

<Frame>
  <img src="/images/s3-storage-architecture.svg" alt="S3 Storage Architecture" />
</Frame>

### Rootfs Image Structure

Each rootfs is an ext4 filesystem image containing:

```
rootfs-python.ext4
├── bin/                    # Core binaries
├── etc/
│   └── systemd/system/
│       └── infra.operator.service
├── lib/                    # Shared libraries
├── usr/
│   ├── bin/
│   │   └── python3
│   └── local/
│       └── bin/
│           └── infra.operator
└── var/                    # Variable data
```

## Environment Variables

The executor sets these environment variables for code execution:

```go
cmd.Env = append(os.Environ(),
    "HOME=/tmp",
    "GOCACHE=/tmp/go-cache",
    "GOPATH=/tmp/go",
    "GOROOT=/usr/local/go",
    "CARGO_HOME=/opt/cargo",
    "RUSTUP_HOME=/opt/rustup",
    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin:/opt/cargo/bin",
)
```

## Future Architecture

### Planned Enhancements

<CardGroup cols={2}>
  <Card title="VM Pool" icon="layer-group">
    Pre-booted VM pool for instant job execution
  </Card>
  <Card title="Snapshot Restore" icon="clock-rotate-left">
    Sub-100ms warm starts from snapshots
  </Card>
  <Card title="Control Plane" icon="server">
    Distributed job queue and VM management
  </Card>
  <Card title="Metrics & Tracing" icon="chart-line">
    OpenTelemetry integration with trace_id propagation
  </Card>
</CardGroup>
